---
title: "Mini-Project #03: NYC Tree Canopy Analysis"
page-layout: article
format:
  html:
    toc: true
    toc-location: right
    toc-title: "On this page"
    toc-depth: 4
    toc-sticky: true
    self-contained: false
    grid:
      body-width: 850px
      margin-width: 320px
---

## üß∞ Project Overview

**Overarching Question:** 

How are trees distributed across NYC‚Äôs council districts, where are maintenance needs most acute, and what district-level program would best preserve canopy and public safety?

New York City‚Äôs green spaces are a defining feature of its urban landscape from tree-lined streets to expansive parks that shape livability. In this mini-project, I‚Äôll explore the **NYC TreeMap dataset** to visualize and analyze how these natural assets are distributed across boroughs and council districts. I‚Äôll then propose a new **NYC Parks Department program** designed to expand the benefits of trees to all New Yorkers.

![Aerial view of Central Park, NYC ‚Äî symbolizing the city‚Äôs green canopy.](images/central-park.jpg){fig-align="center" width="85%"}

```{=html}
<style>
.quarto-figure { text-align: center; }
.quarto-figure img { display: block; margin-left: auto; margin-right: auto; }
.quarto-figure figcaption, .figure-caption { text-align: center; margin-top: .4rem; }
</style>
```

------------------------------------------------------------------------

### üéØ Project Goals & Outcomes

By the end of this mini-project, I will:

-   üß© Programmatically acquire and process real-world geospatial data using the **NYC Open Data API**\
-   üå≥ Combine multiple spatial datasets to understand NYC‚Äôs urban forest composition\
-   üìä Create compelling data visualizations using `ggplot2` and `sf`\
-   üèõÔ∏è Translate data-driven insights into an actionable **policy proposal** for the Parks Department

------------------------------------------------------------------------

### üîç Data Analysis Framework

This project follows the **STA 9750 data-analysis workflow**, which builds practical data-science skills step-by-step:

1.  **Data Ingestion & Cleaning** ‚Äì Transform raw datasets into standardized R data frames\
2.  **Data Combination & Alignment** ‚Äì Merge tree points with NYC council-district boundaries\
3.  **Descriptive Analysis** ‚Äì Compute statistics on tree counts, density, and species diversity\
4.  **Visualization** ‚Äì Use layered `geom_sf()` maps and graphics to communicate insights\
5.  **Policy Design** ‚Äì Develop a concise data-supported proposal for improving NYC‚Äôs tree coverage

---

## üåê Data Acquisition 

This section focuses on collecting and preparing the core spatial data needed for NYC‚Äôs tree canopy analysis. Both dataset the **City Council District boundaries** and **the Forestry Tree Points** are retrieved from **official NYC Open Data sources**. They are cleaned, standardized to the WGS84 coordinate system, and stored locally to support reproducible geospatial analysis and visualization.

---

### Task 01: üó∫Ô∏è Download NYC City Council Districts Dataset

The **NYC City Council Districts** shapefile provides the geographic boundaries for all **51 council districts** in New York City. It is downloaded from the NYC Department of City Planning, unzipped, and converted into a WGS84 coordinate system for compatibility. These polygons will later be used to spatially join and summarize the tree data by district.

This analysis uses the **official ‚ÄúCity Council (Clipped to Shoreline)‚Äù shapefile ‚Äî Latest Release 25C (August 2025)**, downloaded from the NYC Department of City Planning‚Äôs [City Council dataset portal](https://www.nyc.gov/content/planning/pages/resources/datasets/city-council) using the ZIP file `nycc_25c.zip`. To respect the data provider‚Äôs servers, this script downloads the ZIP file only once and reuses the cached copy in future renders. After extraction, the boundaries are converted from the local NYC projection to **WGS 84 (EPSG 4326)** to ensure alignment with other geospatial layers. If plotting proves slow, I can simplify the polygons using `st_simplify(dTolerance = 5)` without visible loss of detail.

------------------------------------------------------------------------

```{r}
#| label: task1-districts
#| cache: true
#| code-fold: true
#| results: 'hide'
#| message: false
#| warning: false
#| code-summary: "üó∫Ô∏è Click to see the Council Districts download + results"

suppressPackageStartupMessages({
  library(tidyverse)
  library(sf)
})

# --- Configuration (replace with the latest ZIP from NYC Planning ‚Üí 'Clipped to Shoreline') ---
COUNCIL_ZIP_URL <- "https://s-media.nyc.gov/agencies/dcp/assets/files/zip/data-tools/bytes/city-council/nycc_25c.zip"

# --- Helpers ---
say <- function(...) cat(paste0(format(Sys.time(), "%H:%M:%S"), " | ", sprintf(...), "\n"))
file_ready <- function(p) file.exists(p) && isTRUE(file.info(p)$size > 0)
to_wgs84 <- function(x) st_transform(x, crs = "WGS84")

download_council_districts <- function(
  zip_url,
  out_dir = "data/mp03",
  unzip_dir = file.path(out_dir, "council_shp"),
  simplify_tolerance_m = NULL   # optional speed-up; keep NULL for full-precision shapes
){
  if (identical(zip_url, "PASTE_THE_CITY_COUNCIL_CLIPPED_TO_SHORELINE_ZIP_URL_HERE")) {
    stop("Please set COUNCIL_ZIP_URL to the official 'Clipped to Shoreline' ZIP from NYC Planning.")
  }
  dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
  zip_path <- file.path(out_dir, "council_districts.zip")

  # Download once (be respectful of the provider)
  if (!file_ready(zip_path)) {
    say("Downloading council districts (zip)‚Ä¶")
    download.file(zip_url, destfile = zip_path, mode = "wb", quiet = TRUE)
  } else {
    say("Reusing cached zip: %s", zip_path)
  }

  # Unzip once
  if (!dir.exists(unzip_dir) || length(list.files(unzip_dir, "\\.shp$", full.names = TRUE)) == 0) {
    say("Unzipping shapefiles‚Ä¶")
    unzip(zip_path, exdir = unzip_dir)
  } else {
    say("Shapefiles already unzipped at: %s", unzip_dir)
  }

  # Read and transform to WGS84
  shp <- list.files(unzip_dir, pattern = "\\.shp$", full.names = TRUE)
  stopifnot(length(shp) >= 1)
  say("Reading shapefile: %s", basename(shp[1]))
  districts <- sf::st_read(shp[1], quiet = TRUE) |> to_wgs84()

  # Optional simplification (assignment hint)
  if (!is.null(simplify_tolerance_m)) {
    say("Simplifying geometry with dTolerance = %s m‚Ä¶", simplify_tolerance_m)
    districts <- districts |> mutate(geometry = st_simplify(geometry, dTolerance = simplify_tolerance_m))
  }

  districts
}

# ---- Run Task 1 (full-precision by default) ----
districts <- download_council_districts(
  zip_url = COUNCIL_ZIP_URL,
  simplify_tolerance_m = NULL  # set to 5 later if plotting feels slow
)

# ---- Combined results (success / warn / error-style messages) ----
epsg_val <- tryCatch(st_crs(districts)$epsg, error = function(e) NA_integer_)
is_wgs84 <- isTRUE(epsg_val == 4326) || grepl("WGS", paste0(st_crs(districts)$input), ignore.case = TRUE)
n_feat <- tryCatch(nrow(districts), error = function(e) NA_integer_)

if (!is.na(n_feat) && is_wgs84 && n_feat >= 51) {
  cat(sprintf("‚úÖ Successfully downloaded and transformed the City Council District boundaries to WGS84.\n"))
  cat(sprintf("‚úÖ Detected %d polygon features (expected ‚â• 51). Ready for spatial ops & visualization.\n", n_feat))
  cat(sprintf("‚ÑπÔ∏è  CRS: %s (EPSG: %s)\n", st_crs(districts)$input %||% "unknown", epsg_val %||% NA_integer_))
} else if (!is.na(n_feat)) {
  if (!is_wgs84) {
    cat("‚ö†Ô∏è Districts loaded but CRS is not WGS84. Please ensure st_transform(..., crs = 'WGS84').\n")
  }
  if (n_feat < 51) {
    cat(sprintf("‚ö†Ô∏è Districts loaded but feature count is low (%d < 51). Verify I am using the 'Clipped to Shoreline' dataset.\n", n_feat))
  }
} else {
  cat("‚ùå Districts could not be verified. Re-run the download step and check the ZIP URL.\n")
}

saveRDS(districts, file = "data/mp03/districts_wgs84_25c.rds")

```

**üßæ Result:**

```{r}
#| label: task1-districts-result
#| dependson: "task1-districts"
#| echo: false
#| cache: false
#| message: false
#| warning: false

suppressPackageStartupMessages({ library(rlang) })

# Safety guard
if (!exists("districts")) {
  cat("‚ö†Ô∏è Districts object not available yet ‚Äî run the full document (not just this chunk).\n")
  knitr::knit_exit()
}

# ---- Result summary ----
epsg_val <- tryCatch(sf::st_crs(districts)$epsg, error = function(e) NA_integer_)
is_wgs84 <- isTRUE(epsg_val == 4326) || grepl("WGS", paste0(sf::st_crs(districts)$input), ignore.case = TRUE)
n_feat   <- tryCatch(nrow(districts), error = function(e) NA_integer_)

if (!is.na(n_feat) && is_wgs84 && n_feat >= 51) {
  cat("‚úÖ Successfully downloaded and transformed the City Council District boundaries to WGS84.\n")
  cat(sprintf("‚úÖ Detected %d polygon features (expected ‚â• 51). Ready for spatial ops & visualization.\n", n_feat))
  cat(sprintf("‚ÑπÔ∏è CRS: %s (EPSG: %s)\n", sf::st_crs(districts)$input %||% "unknown", epsg_val %||% NA_integer_))
} else if (!is.na(n_feat)) {
  if (!is_wgs84) cat("‚ö†Ô∏è Districts loaded but CRS is not WGS84. Please ensure st_transform(..., crs='WGS84').\n")
  if (n_feat < 51) cat(sprintf("‚ö†Ô∏è Feature count is low (%d < 51). Verify dataset integrity.\n", n_feat))
} else {
  cat("‚ùå Districts could not be verified. Re-run the download step and check the ZIP URL.\n")
}

```

------------------------------------------------------------------------

> ‚öôÔ∏è *This chunk is cached for speed. I will clear the cache and re-run the entire document before submission to ensure full reproducibility.*

### Task 02:üå≥ NYC Tree Points

The **Forestry Tree Points dataset** is sourced directly from the **NYC Open Data API (SODA2 GeoJSON endpoint)**. It contains detailed information on individual trees including their species, health, location, and maintenance status across all five boroughs. This dataset is programmatically downloaded in paged batches to ensure full coverage, responsibly cached to minimize server load, and aligned with WGS84 for seamless spatial joins with the district boundaries.

The **Forestry Tree Points** dataset was accessed directly through the NYC Open Data **SODA2 API**. The endpoint URL (`https://data.cityofnewyork.us/resource/hn5i-inap.geojson`) was obtained via the site‚Äôs **Export ‚Üí API Endpoint ‚Üí GeoJSON (SODA2)** option. All requests are made with the **`httr2`** package (explicitly required by the assignment) rather than `httr` or `RSocrata`. The script paginates through the full dataset using `$limit = 10 000` and incrementing `$offset` until the last page contains fewer rows than the limit‚Äîensuring complete yet polite retrieval. Each page is saved locally under a consistent naming scheme such as `trees_<offset>_<limit>.geojson` and reused on reruns to avoid repeated downloads.

------------------------------------------------------------------------

```{r}
#| label: task2-trees
#| cache: true
#| code-fold: true
#| results: 'hide'
#| message: false
#| warning: false
#| code-summary: "üå≥ Click to see the Tree Points full-dataset download + results (httr2 + paging)"
suppressPackageStartupMessages({
  library(httr2)
  library(glue)
  library(sf)
  library(dplyr)
  library(purrr)
})

say <- function(...) cat(paste0(format(Sys.time(), "%H:%M:%S"), " | ", sprintf(...), "\n"))
file_ready <- function(p) file.exists(p) && isTRUE(file.info(p)$size > 0)
to_wgs84 <- function(x) st_transform(x, crs = "WGS84")

download_tree_points <- function(
  base_url  = "https://data.cityofnewyork.us/resource/hn5i-inap.geojson",  # GeoJSON (SODA2)
  out_dir   = "data/mp03",
  page_limit = 10000,    # balanced for stability & speed
  max_pages  = Inf,      # safety cap if needed
  full_data  = TRUE      # TRUE = pull everything; FALSE = first page only (dev)
){
  dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
  say("Found %d cached page file(s).", length(Sys.glob(file.path(out_dir, "trees_*_*.geojson"))))
  all_files <- character()
  offset <- 0
  page <- 1

  say("Starting paginated download from NYC OpenData (GeoJSON, httr2)‚Ä¶")

  repeat {
    target <- file.path(out_dir, glue("trees_{sprintf('%05d', offset)}_{page_limit}.geojson"))

    if (!file_ready(target)) {
      say("Requesting page %d (offset=%d, limit=%d)‚Ä¶", page, offset, page_limit)
      req <- request(base_url) |>
        req_url_query(`$limit` = page_limit, `$offset` = offset)
      resp <- req |>
        req_retry(max_tries = 3, backoff = ~ runif(1, 0.3, 0.8)) |>
        req_perform()
      writeBin(resp_body_raw(resp), target)
      Sys.sleep(0.2)
    } else {
      say("Using cached page: %s", basename(target))
    }

    all_files <- c(all_files, target)

    # Peek row count to find stop condition: last page if n < limit
    g <- tryCatch(suppressMessages(st_read(target, quiet = TRUE)), error = function(e) NULL)
    n_g <- if (!is.null(g)) nrow(g) else 0
    say("Page %d rows: %d", page, n_g)

    if (!full_data) break
    if (n_g < page_limit) {
      say("Reached final page (rows=%d < limit=%d).", n_g, page_limit)
      break
    }

    offset <- offset + page_limit
    page   <- page + 1
    if (page > max_pages) {
      say("Stopped early due to max_pages=%s", as.character(max_pages))
      break
    }
  }

# --- Safe combine with type normalization ---
say("Reading %d GeoJSON page(s)‚Ä¶", length(all_files))
pages <- purrr::map(all_files, ~ suppressMessages(st_read(.x, quiet = TRUE)))

# Find inconsistent column types (ignore geometry)
col_classes <- purrr::map(pages, ~ purrr::map_chr(., ~ paste(class(.x), collapse = "/")))
all_names   <- Reduce(union, lapply(col_classes, names))
pages <- purrr::map(pages, ~ {
  missing <- setdiff(all_names, names(.x))
  if (length(missing)) .x[missing] <- NA
  .x[all_names]
})

col_classes <- purrr::map(pages, ~ purrr::map_chr(., ~ paste(class(.x), collapse = "/")))
mixed_cols <- setdiff(
  names(Filter(function(v) length(unique(v)) > 1,
               purrr::transpose(col_classes) |> purrr::map(unlist))),
  c("geometry")
)

if (length(mixed_cols)) {
  say("Normalizing mixed-type columns to character: %s", paste(mixed_cols, collapse = ", "))
  pages <- purrr::map(pages, ~ dplyr::mutate(.x, dplyr::across(all_of(mixed_cols), as.character)))
}

# Combine and transform
trees <- dplyr::bind_rows(pages)
trees <- to_wgs84(trees)
say("Combined rows: %d | CRS: %s", nrow(trees), st_crs(trees)$input)
# basic integrity validation
geom_type <- unique(as.character(st_geometry_type(trees)))
if (!identical(geom_type, "POINT")) cat("‚ö†Ô∏è Expected POINT geometries; got: ", geom_type, "\n")
if (st_crs(trees)$epsg != 4326) cat("‚ö†Ô∏è CRS is not EPSG:4326 (WGS84).\n")
trees

}

# ---- Run Task 2 (FULL DATASET) ----
trees <- download_tree_points(
  page_limit = 10000,   # required for full dataset paging
  full_data  = TRUE     # pull all pages until the last page < limit
)

# ---- Results summary (success / warn / error) ----
gjs <- Sys.glob("data/mp03/trees_*_*.geojson")
epsg_val <- tryCatch(st_crs(trees)$epsg, error = function(e) NA_integer_)
is_wgs84 <- isTRUE(epsg_val == 4326) || grepl("WGS", paste0(st_crs(trees)$input), ignore.case = TRUE)
n_rows <- tryCatch(nrow(trees), error = function(e) NA_integer_)

last_file <- if (length(gjs)) gjs[order(gjs)][length(gjs)] else NA_character_
last_rows <- if (!is.na(last_file)) {
  t_last <- tryCatch(suppressMessages(st_read(last_file, quiet = TRUE)), error = function(e) NULL)
  if (!is.null(t_last)) nrow(t_last) else NA_integer_
} else NA_integer_

if (!is.na(n_rows) && n_rows > 0) {
  if (is_wgs84) {
    cat(sprintf("‚úÖ Successfully downloaded the full Tree Points dataset in WGS84 (EPSG:4326).\n"))
  } else {
    cat("‚ö†Ô∏è Tree Points loaded but CRS is not WGS84. Ensure st_transform(..., crs='WGS84').\n")
  }

  cat(sprintf("‚úÖ Combined total: %s rows across %d saved page file(s).\n",
            format(n_rows, big.mark = ","), length(gjs)))
    if (!is.na(last_rows)) {
    if (grepl("_10000\\.geojson$", last_file)) {
      if (last_rows < 10000) {
        cat(sprintf("‚úÖ Stop condition satisfied: last page has %,d rows (< 10,000).\n", last_rows))
      } else {
        cat("‚ö†Ô∏è Last page equals 10,000 rows; I may need additional pages. Re-run to continue.\n")
      }
    } else {
      cat(sprintf("‚ÑπÔ∏è Last page rows detected: %,d.\n", last_rows))
    }
  } else {
    cat("‚ö†Ô∏è Could not validate last page size. Files exist but unreadable; try re-running the download.\n")
  }
} else if (length(gjs) == 0) {
  cat("‚ùå Tree Points not found on disk. Run Task 2 (httr2 + paging + save pages).\n")
} else {
  cat("‚ö†Ô∏è Tree Points files exist, but the combined object is empty. Re-run the download and combine steps.\n")
}
saveRDS(trees, file = "data/mp03/trees_wgs84_combined.rds")

```

------------------------------------------------------------------------

For development runs, I can switch `full_data = FALSE` to fetch only the first 10 000 rows, which enables faster debugging on smaller machines. Before the final submission, I re-enable `full_data = TRUE` to ensure analysis covers all available trees. After acquisition, I reviewed the dataset documentation and noted key variables used later in the analysis:\
- `spc_common` ‚Äì common species name\
- `health` ‚Äì tree health rating (`Good`, `Fair`, `Poor`)\
- `status` ‚Äì whether the tree is alive, dead, or stumped\
- `genusspecies` ‚Äì scientific species name\
- `tpcondition` ‚Äì overall condition assessment\
These fields will guide calculations of species distribution and maintenance priorities.\
All chunks are cached (`cache: true`) for speed, but I will **clear the cache and re-render from scratch** before submission to guarantee full reproducibility.

------------------------------------------------------------------------

**üßæ Result:**

```{r}
#| label: task2-trees-results
#| echo: false
#| cache: false
#| message: false
#| warning: false

# Quick result summary

gjs <- if (exists("gjs")) gjs else Sys.glob("data/mp03/trees_*_*.geojson")
epsg_val <- tryCatch(sf::st_crs(trees)$epsg, error = function(e) NA_integer_)
is_wgs84 <- isTRUE(epsg_val == 4326) || grepl("WGS", paste0(sf::st_crs(trees)$input), ignore.case = TRUE)
n_rows <- tryCatch(nrow(trees), error = function(e) NA_integer_)

if (!is.na(n_rows) && n_rows > 0) {
cat("‚úÖ Successfully downloaded the full Tree Points dataset in WGS84 (EPSG:4326).\n")
cat(sprintf("‚úÖ Combined total: %s rows across %d saved page file(s).\n",
format(n_rows, big.mark=","), length(gjs)))
cat("‚úÖ Data is aligned and ready for geospatial joins with council districts.\n")
} else {
cat("‚ö†Ô∏è Tree Points download incomplete ‚Äî please re-run the task.\n")
}

```

------------------------------------------------------------------------

## üß≠ Data Integration and Initial Exploration

For performance and reproducibility, I reload the processed **Council Districts** and **Tree Points** from the artifacts saved in **data/mp03/** when available. This avoids rerunning the full download pipelines each time the document is rendered.

```{r}
#| label: load-prepared-artifacts
#| code-fold: true
#| code-summary: "üì¶ Click to load cached district & tree data (faster re-runs)"
#| cache: true
#| echo: false
#| message: false
#| warning: false

# Prefer loading cached artifacts if available (faster, fully reproducible)

if (file.exists("data/mp03/districts_wgs84_25c.rds")) {
districts <- readRDS("data/mp03/districts_wgs84_25c.rds")
cat("‚úÖ Loaded cached Council Districts (WGS84, Release 25C)\n")
} else {
cat("‚ö†Ô∏è Council Districts not found ‚Äî please re-run Task 1.\n")
}

if (file.exists("data/mp03/trees_wgs84_combined.rds")) {
trees <- readRDS("data/mp03/trees_wgs84_combined.rds")
cat("‚úÖ Loaded cached Tree Points (WGS84, combined full dataset)\n")
} else {
cat("‚ö†Ô∏è Tree Points not found ‚Äî please re-run Task 2.\n")
}

```

**Recording Quality.** Checked status/species, geometry validity; dropped only unmatched districts for summaries.

**Sampling Quality.** Full dataset for stats; sample used *only* for map rendering performance.

**Suitability.** District polygons = budget unit; tree points = condition/species; EC#02 = operational load.

------------------------------------------------------------------------

### üåø Task 3: Mapping NYC Trees ‚Äî Plot All Tree Points

Before performing district-level analysis, it‚Äôs important to visualize how trees are distributed across the city. This plot uses two spatial layers, the **City Council Districts** (polygons) and the **Forestry Tree Points** (points). To improve performance, only a sample of 50,000 trees is displayed during development, though the full dataset can be rendered for the final map.

```{r}
#| label: task3-map-all-trees-ggplot
#| cache: true
#| code-fold: true
#| code-summary: "üåø Render: Publication map (district polygons + tree points)"
#| message: false
#| warning: false
#| fig-width: 9
#| fig-height: 9

suppressPackageStartupMessages({
  library(ggplot2); library(dplyr); library(sf); library(scales)
})

stopifnot(inherits(districts, "sf"), inherits(trees, "sf"))
districts <- sf::st_transform(districts, "WGS84")
trees     <- sf::st_transform(trees, "WGS84")

# Sample for speed during development (set to nrow(trees) for final)
sample_n_points <- min(100000, nrow(trees))
set.seed(9750)
trees_plot <- dplyr::slice_sample(trees, n = sample_n_points)

districts <- sf::st_simplify(districts, dTolerance = 5)
ggplot() +
  # Layer 1: council districts (POLYGON)
  geom_sf(data = districts, fill = "grey97", color = "grey55", linewidth = 0.35) +
  # Tiny white halo so points pop on light basemap
  geom_sf(data = trees_plot, color = "white", alpha = 0.22, size = 0.22) +
  # Layer 2: tree points (POINT)
  geom_sf(data = trees_plot, color = "#1B7F3A", alpha = 0.35, size = 0.15) +
  coord_sf(expand = FALSE) +
  labs(
    title    = "NYC Trees Across Council Districts",
    subtitle = paste0("Showing ", comma(nrow(trees_plot)),
                      " tree points over official Council District boundaries (WGS 84)"),
    caption  = "Sources: NYC Open Data (Forestry Tree Points) ‚Ä¢ NYC DCP (Council Districts)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title      = element_text(face = "bold", size = 16),
    plot.subtitle   = element_text(margin = margin(b = 8)),
    panel.background = element_rect(fill = "aliceblue", color = NA),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.title = element_blank()
  )

```

***Note: Both spatial layers are transformed to WGS 84 for consistency, and district boundaries are lightly simplified (dTolerance = 5) to improve rendering performance. The final version uses the full NYC tree dataset.***

### üèôÔ∏è Task 4: District-Level Analysis of Tree Coverage

After mapping all tree points across New York City, the next step is to perform a district-level spatial analysis that links each individual tree to its corresponding City Council District. Using spatial joins and grouped summaries, this section quantifies how tree distribution varies across districts and boroughs. Key exploratory questions include identifying which districts have the most trees, the highest density, or the largest fraction of dead trees. The analysis also examines species composition by borough‚Äîparticularly in Manhattan‚Äîand pinpoints the tree located closest to Baruch College using spatial distance calculations in WGS 84 coordinates.

### üß© Exploratory Questions Overview
Join together the tree points and district boundaries using the steps outlined above and answer the following five exploratory questions:

```{r}
#| label: task4-join-and-setup
#| code-fold: true
#| code-summary: "üß≠ Click to see: spatial join (trees ‚Üî districts) + helpers"
#| cache: true
#| message: false
#| warning: false

suppressPackageStartupMessages({
  library(dplyr); library(sf); library(stringr); library(tidyr)
})

stopifnot(inherits(districts, "sf"), inherits(trees, "sf"))

# Ensure WGS84 for both layers (defensive)
to_wgs84 <- function(x) {
  if (is.na(sf::st_crs(x))) stop("CRS missing on object; please ensure CRS is set before transforming.")
  if (sf::st_crs(x)$epsg != 4326) sf::st_transform(x, crs = "WGS84") else x
}
districts <- to_wgs84(districts)
trees     <- to_wgs84(trees)

# Identify district id & area columns (defensive to name variants)
area_col <- intersect(names(districts), c("Shape_Area","shape_area","shapearea","AREA","area"))
if (length(area_col) == 0) {
  districts <- districts %>% mutate(Shape_Area = as.numeric(sf::st_area(geometry)))
  area_col <- "Shape_Area"
}
district_id_col <- intersect(names(districts), c("CounDist","coundist","coun_dist","DISTRICT","council_district","c_district"))
if (length(district_id_col) == 0) {
  candidate_ints <- names(dplyr::select(districts, where(is.numeric)))
  guess <- purrr::keep(candidate_ints, ~ all(districts[[.x]] %% 1 == 0, na.rm = TRUE))
  if (length(guess)) district_id_col <- guess[1] else stop("Could not find a council district id column; please map it manually.")
}

# Spatial join: assign each tree to its district (POINTs first, REGIONS second ‚Üí st_intersects)
trees_joined <- sf::st_join(
  trees,
  districts %>% dplyr::select(!!district_id_col, !!area_col, geometry),
  join = sf::st_intersects,
  left = TRUE
)

# Normalize names used downstream
trees_joined <- trees_joined %>%
  rename(
    district_id = !!district_id_col,
    Shape_Area  = !!area_col
  )

# Minimal cleaning: dead flag & species field (defensive to naming)
status_col  <- names(trees_joined)[names(trees_joined) %in% c("status","tree_status","tpcondition")]
species_col <- names(trees_joined)[names(trees_joined) %in% c("spc_common","common","species_common","species")]

trees_joined <- trees_joined %>%
  mutate(
    status_chr  = if (length(status_col)) as.character(.data[[status_col[1]]]) else NA_character_,
    dead_flag   = ifelse(!is.na(status_chr) & str_detect(str_to_lower(status_chr), "dead"), 1L, 0L),
    spc_common_ = if (length(species_col)) as.character(.data[[species_col[1]]]) else NA_character_
  ) %>%
  relocate(district_id, Shape_Area, spc_common_, dead_flag, .before = 1)

# Save counts for the status chunk
joined_rows <- nrow(trees_joined)
n_districts <- dplyr::n_distinct(trees_joined$district_id)
```

```{r}
#| label: task4-join-status
#| echo: false
#| code-fold: false
#| cache: false
#| results: 'asis'

cat("‚úÖ Spatial join complete: trees linked to council districts.\n")
cat(sprintf("   Joined rows: %s | Distinct districts found: %s\n",
            format(joined_rows, big.mark=","), n_districts))

```

------------------------------------------------------------------------

***The following analysis summarizes the five key exploratory questions based on the spatially joined tree and district data.***

```{r}
#| label: task4-summaries
#| code-fold: true
#| code-summary: "üß© District-level results (Q1‚ÄìQ5)"
#| cache: true
#| message: false
#| warning: false

suppressPackageStartupMessages({
  library(dplyr); library(sf); library(tidyr); library(glue)
})

# Safety: drop trees without a matched district_id (e.g., off-shore/invalid points)
tj <- trees_joined %>% filter(!is.na(district_id))

# Derive one area value per district in m¬≤ (NY State Plane EPSG:2263 ‚Üí meters)
district_areas_m2 <- districts |>
  sf::st_transform(2263) |>
  transmute(district_id = .data[[district_id_col]],
            area_m2 = as.numeric(sf::st_area(geometry))) |>
  sf::st_drop_geometry() |>
  distinct(district_id, .keep_all = TRUE)

# Borough lookup (using detected district_id_col)
district_lookup_min <- districts |>
  sf::st_drop_geometry() |>
  transmute(
    district_id = .data[[district_id_col]],
    Borough = dplyr::case_when(
      .data[[district_id_col]] %in%  1:10 ~ "Manhattan",
      .data[[district_id_col]] %in% 11:18 ~ "Bronx",
      .data[[district_id_col]] %in% 19:32 ~ "Queens",
      .data[[district_id_col]] %in% 33:48 ~ "Brooklyn",      # 33‚Äì48
      .data[[district_id_col]] %in% 49:51 ~ "Staten Island",# 49‚Äì51
      TRUE                               ~ NA_character_
    )
  )

# Q1. Which council district has the most trees?

q1_counts <- tj %>%
  st_drop_geometry() %>%
  count(district_id, name = "n_trees") %>%
  arrange(desc(n_trees))

q1_top <- q1_counts %>%
  left_join(district_lookup_min, by = "district_id") %>%
  slice_head(n = 1)

cat(glue("Q1) Most trees ‚Üí District {q1_top$district_id} ({q1_top$Borough}) ",
         "with {format(q1_top$n_trees, big.mark=',')} trees.\n"))

# Q2. Highest tree density (trees per km¬≤)
q2_density <- tj %>%
  st_drop_geometry() %>%
  count(district_id, name = "n_trees") %>%
  left_join(district_areas_m2, by = "district_id") %>%
  mutate(density = n_trees / (area_m2 / 1e6)) %>%  # trees per km¬≤
  arrange(desc(density))

scale_label <- " per km¬≤"

q2_top <- q2_density %>%
  left_join(district_lookup_min, by = "district_id") %>%
  slice_head(n = 1)

cat(glue("Q2) Highest density ‚Üí District {q2_top$district_id} ({q2_top$Borough}) ",
         "with {round(q2_top$density, 2)}{scale_label}.\n"))

# Q3. Highest fraction of dead trees

q3_dead <- tj %>%
  st_drop_geometry() %>%
  group_by(district_id) %>%
  summarize(
    n_trees = dplyr::n(),
    dead_fraction = mean(dead_flag == 1, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(desc(dead_fraction))

q3_top <- q3_dead %>%
  left_join(district_lookup_min, by = "district_id") %>%
  slice_head(n = 1)

cat(glue("Q3) Highest dead fraction ‚Üí District {q3_top$district_id} ({q3_top$Borough}) ",
         "at {scales::percent(q3_top$dead_fraction, accuracy = 0.1)}.\n"))

# Q4. Most common tree species in Manhattan

borough_map <- function(d) dplyr::case_when(
  d %in%  1:10 ~ "Manhattan",
  d %in% 11:18 ~ "Bronx",
  d %in% 19:32 ~ "Queens",
  d %in% 33:48 ~ "Brooklyn",      # 33‚Äì48
  d %in% 49:51 ~ "Staten Island", # 49‚Äì51
  TRUE         ~ NA_character_
)

tj_borough <- tj %>% mutate(borough = borough_map(district_id))

q4_manhattan_top <- tj_borough %>%
  filter(borough == "Manhattan", !is.na(spc_common_)) %>%
  st_drop_geometry() %>%
  count(spc_common_, sort = TRUE, name = "n") %>%
  slice_head(n = 1)

if (nrow(q4_manhattan_top)) {
  cat(glue("Q4) Most common species in Manhattan ‚Üí {q4_manhattan_top$spc_common_} ",
           "({format(q4_manhattan_top$n, big.mark=',')} trees).\n"))
} else {
  cat("Q4) Could not determine common species in Manhattan (no species data).\n")
}

# Q5. Species of the tree closest to Baruch (with Borough)

sf::sf_use_s2(TRUE)  # great-circle distances

new_st_point <- function(lat, lon){
  sf::st_sfc(sf::st_point(c(lon, lat)), crs = "WGS84")
}
baruch_pt <- new_st_point(lat = 40.7403, lon = -73.9839)

# Ensure same CRS and drop empties
tj_wgs <- tj %>%
  sf::st_transform("WGS84") %>%
  dplyr::filter(!sf::st_is_empty(geometry))

# Compute distances to a single point (no by_element)
dist_vec <- as.numeric(sf::st_distance(sf::st_geometry(tj_wgs), baruch_pt))

closest_row <- tj_wgs %>%
  dplyr::mutate(distance_m = dist_vec) %>%
  dplyr::arrange(distance_m) %>%
  dplyr::slice_head(n = 1) %>%
  sf::st_drop_geometry() %>%
  dplyr::left_join(district_lookup_min, by = "district_id")  # add Borough

if (nrow(closest_row)) {
  nearest_species <- closest_row$spc_common_
  nearest_d_m    <- round(closest_row$distance_m, 1)
  nearest_dist   <- closest_row$district_id
  nearest_boro   <- closest_row$Borough
  cat(glue("Q5) Closest tree to Baruch ‚Üí Species: {ifelse(is.na(nearest_species), 'Unknown', nearest_species)} ",
         "at {nearest_d_m} meters (District {nearest_dist}, {nearest_boro}).\n"))
} else {
  cat("Q5) Could not compute closest tree (no matched trees).\n")
}

```

------------------------------------------------------------------------

**üìò Summary:** This section presents three concise tables summarizing the **Top NYC Council Districts**. In the urban forestry dataset. Each table integrates Borough information for better interpretability and spatial comparison.

```         
‚Ä¢ Q1 shows the **Top districts with the highest total tree counts**, highlighting areas with the largest overall urban canopy.
‚Ä¢ Q2 identifies the **Top districts by tree density** (trees per km¬≤), showcasing regions with the most concentrated greenery.
‚Ä¢ Q3 highlights the **Top districts with the highest proportion of dead trees**, indicating locations that may require greater maintenance attention.
```

```{r}
#| label: task4-tabular-outputs
#| code-fold: true
#| code-summary: "üìÑ Tables with Borough & Key Metrics (Top 10)"
#| cache: true
#| message: false
#| warning: false

suppressPackageStartupMessages({ library(dplyr); library(knitr); library(stringr) })

# Build lookup from actual columns
district_lookup <- districts |>
  sf::st_drop_geometry() |>
  transmute(
    district_id = .data[[district_id_col]],
    Borough = dplyr::case_when(
      .data[[district_id_col]] %in%  1:10 ~ "Manhattan",
      .data[[district_id_col]] %in% 11:18 ~ "Bronx",
      .data[[district_id_col]] %in% 19:32 ~ "Queens",
      .data[[district_id_col]] %in% 33:48 ~ "Brooklyn",      # 33‚Äì48
      .data[[district_id_col]] %in% 49:51 ~ "Staten Island", # 49‚Äì51
      TRUE                               ~ NA_character_
    )
  ) |>
  distinct()

# Q1: Most trees 
q1_table <- q1_counts |>
  left_join(district_lookup, by = "district_id") |>
  relocate(Borough, .after = district_id)

kable(
  head(q1_table, 10),
  caption = "Q1: Districts by total tree count (Top 10) ‚Äî with Borough"
)

# Q2: Highest density
q2_table <- q2_density |>
  left_join(district_lookup, by = "district_id") |>
  select(district_id, Borough, density)

kable(
  head(q2_table, 10),
  caption = paste0("Q2: Tree density (Top 10", scale_label, ") ‚Äî with Borough")
)

# Q3: Highest fraction of dead trees
q3_table <- q3_dead |>
  mutate(dead_pct = scales::percent(dead_fraction, accuracy = 0.1)) |>
  left_join(district_lookup, by = "district_id") |>
  select(district_id, Borough, n_trees, dead_pct)

kable(
  head(q3_table, 10),
  caption = "Q3: Dead tree fraction (Top 10) ‚Äî with Borough"
)
```

------------------------------------------------------------------------

### üå≥ Task 5: NYC Parks Proposal ‚Äî District 39 Tree Renewal Initiative

#### One-Page Summary ‚Äî District 39 Tree Renewal Initiative

**Goal.** Preserve canopy and public safety in District 39 by replacing dead/aging trees, removing stumps, replanting gap blocks/medians, and scheduling annual pruning.

**Scope.** Replace **1,500** dead trees; remove **500** stumps; plant **1,000** resilient trees (e.g., Honeylocust, Ginkgo); and prune **5,000** existing trees annually.

**Why District 39.** Despite NYC‚Äôs highest tree density, District 39 shows an elevated dead-tree share versus peer districts (e.g., 32, 35, 41), indicating urgent renewal needs.

**Expected Impact.** Lower heat-island effects, improved safety, better species resilience/diversity, and long-term canopy stability through routine maintenance.

**Delivery (FY2026).** Phase: stump removal ‚Üí replacements ‚Üí new plantings ‚Üí pruning cycle; community volunteer events; public progress dashboard.

As the Council Member for **District 39 (Brooklyn)**, I propose the **District 39 Tree Renewal Initiative**, a neighborhood-focused effort to improve the balance between canopy coverage and tree health. Although District 39 has the **highest tree density in NYC (‚âà 274 trees per km¬≤)**, many trees are aging or at risk of decline. This project will focus on replacing old or dead trees and introducing new resilient species to ensure long-term canopy stability.

**Proposed scope of work** - Replace **1 500 dead trees** with new resilient species (e.g., Honeylocust, Ginkgo).\
- Plant **1 000 new trees** in sidewalk gaps and open medians.\
- Remove **500 old stumps** to create new planting spaces.\
- Conduct **annual pruning for 5 000 existing trees** to maintain canopy health.

```{r}
#| label: task5-scope-justification
#| code-fold: true
#| code-summary: "üî¢ Data check: D39 dead trees & stumps"
#| echo: false
#| message: false
#| warning: false

d39_counts <- {
  # Start from the filtered data
  tmp <- trees_joined |> dplyr::filter(district_id == 39)

  # Add columns only if they don't exist (same logic as before)
  if (!"genusspecies" %in% names(tmp)) tmp <- dplyr::mutate(tmp, genusspecies = NA_character_)
  if (!"tpcondition"  %in% names(tmp)) tmp <- dplyr::mutate(tmp, tpcondition  = NA_character_)

  # Summaries (unchanged intent)
  tmp |>
    dplyr::mutate(
      genusspecies_chr = ifelse(is.na(genusspecies), "", as.character(genusspecies))
    ) |>
    dplyr::summarise(
      dead_n  = sum(tolower(tpcondition) == "dead", na.rm = TRUE),
      stumps  = sum(grepl("stump", tolower(genusspecies_chr)), na.rm = TRUE),
      total_n = dplyr::n()
    )
}
```

*Justification.* Based on the current inventory, District 39 has roughly **`r d39_counts$dead_n`** dead trees and **`r d39_counts$stumps`** stumps; our targets align to clear this backlog within FY2026.

------------------------------------------------------------------------

#### üó∫Ô∏è District 39 Tree Renewal Focus ‚Äî Zoomed-In Brooklyn Map

This interactive visualization highlights the **tree renewal priority areas** in Brooklyn‚Äôs District 39. Clusters indicate concentrations of aging or dead trees identified for replacement, helping planners target renewal efforts efficiently.

```{r}
#| label: task5-map-d39-leaflet
#| fig-cap: "District 39 ‚Äî interactive Leaflet with base-style switcher, alive/dead layers, clustered points, and optional heatmap."
#| code-fold: true
#| code-summary: "üß≠ Interactive Leaflet (OSM default, pro styling, clustering)"
#| message: false
#| warning: false

suppressPackageStartupMessages({
library(dplyr); library(sf); library(leaflet)
ok_extras <- requireNamespace("leaflet.extras", quietly = TRUE)
})

selected_district <- 39

# ---- Subset, validate, CRS ----

d39_poly  <- districts    |> dplyr::filter(.data[[district_id_col]] == selected_district)
trees_d39 <- trees_joined |> dplyr::filter(district_id == selected_district)
stopifnot(nrow(d39_poly) > 0, nrow(trees_d39) > 0)

d39_poly  <- d39_poly  |> sf::st_make_valid() |> sf::st_transform(4326)
trees_d39 <- trees_d39 |> sf::st_make_valid() |> sf::st_transform(4326)

# ---- Robust status + popup fields ----

if (!"genusspecies" %in% names(trees_d39)) trees_d39$genusspecies <- NA_character_
if (!"riskrating"   %in% names(trees_d39)) trees_d39$riskrating   <- NA_character_

trees_d39 <- trees_d39 |>
mutate(
status = dplyr::case_when(
"dead_flag"   %in% names(trees_d39) & !is.null(dead_flag)   ~ ifelse(dead_flag == 1, "Dead", "Alive"),
"tpcondition" %in% names(trees_d39) & !is.null(tpcondition) ~ ifelse(tolower(tpcondition) == "dead", "Dead", "Alive"),
TRUE ~ "Alive"
),
popup = paste0(
"<b>Status:</b> ", status,
ifelse(!is.na(genusspecies) & genusspecies != "", paste0("<br><b>Species:</b> ", genusspecies), ""),
ifelse(!is.na(riskrating)   & riskrating   != "", paste0("<br><b>Risk:</b> ", riskrating), "")
)
)

# ---- Map (OSM default; extra pro base tiles) ----

m <- leaflet(height = 520, options = leafletOptions(preferCanvas = TRUE)) |>
addTiles(group = "OSM (fallback)") |>
addProviderTiles(providers$CartoDB.Positron,        group = "Carto Positron") |>
addProviderTiles(providers$Esri.WorldGrayCanvas,    group = "Esri Gray") |>
setView(lng = -73.99, lat = 40.66, zoom = 13) |>

# District outline

addPolygons(data = d39_poly, color = "#444", weight = 1.2, fill = FALSE, group = "District 39") |>

# Alive / Dead separate overlays

addCircleMarkers(
data = dplyr::filter(trees_d39, status == "Alive"),
radius = 3, stroke = TRUE, weight = 0.5, opacity = 1, fillOpacity = 0.6,
color = "white", fillColor = "#2E7D32", popup = ~popup, group = "Alive"
) |>
addCircleMarkers(
data = dplyr::filter(trees_d39, status == "Dead"),
radius = 3.5, stroke = 0.5, opacity = 1, fillOpacity = 0.9,
color = "white", fillColor = "#D32F2F", popup = ~popup, group = "Dead"
) |>

# Optional combined clustered overlay (fast on large sets)

addCircleMarkers(
data = trees_d39,
lng = ~sf::st_coordinates(geometry)[,1],
lat = ~sf::st_coordinates(geometry)[,2],
radius = 3, stroke = FALSE, fillOpacity = 0.85,
fillColor = ~ifelse(status == "Dead", "#D32F2F", "#2E7D32"),
popup = ~popup, group = "All Trees (clustered)",
clusterOptions = markerClusterOptions()
)

# ---- Optional dead-tree heatmap (requires leaflet.extras) ----

if (ok_extras) {
dead_xy <- sf::st_coordinates(dplyr::filter(trees_d39, status == "Dead"))
if (nrow(dead_xy) > 0) {
m <- leaflet.extras::addHeatmap(
m, lng = dead_xy[,1], lat = dead_xy[,2],
blur = 18, max = 0.8, radius = 12, group = "Dead Heatmap"
)
}
}

# ---- Controls + legend ----

m <- m |>
addLayersControl(
baseGroups    = c("OSM (fallback)", "Carto Positron", "Esri Gray"),
overlayGroups = c("Alive", "Dead", "All Trees (clustered)", if (ok_extras) "Dead Heatmap"),
options = layersControlOptions(collapsed = FALSE, autoZIndex = TRUE)
) |>
addLegend(position = "bottomright",
colors = c("#2E7D32", "#D32F2F"),
labels = c("Alive", "Dead"),
title  = "Tree Status")

m

```

> ‚öôÔ∏è *Interactive map for District 39 (Brooklyn) showing tree conditions with toggles for Alive/Dead, an optional clustered view for performance, and a dead-tree heatmap layer. Use the base map switcher (OSM default, Carto Positron, Esri Gray) to present a clean, professional backdrop while exploring hotspots that motivate the renewal proposal.* ---

#### üìä Comparative Analysis ‚Äî District 39 vs Nearby Districts

I compare **District 39** against **Districts 32, 35, and 41** on the **dead-tree fraction** to justify the renewal focus. The chart highlights D39, shows the **citywide median** (dashed line), and includes **borough labels**; hover to see exact values.

```{r}
#| label: task5-dead-fraction-advanced
#| fig-cap: "Dead Tree Fraction ‚Äî District 39 vs nearby districts, with borough labels and interactive tooltips."
#| code-fold: true
#| code-summary: "üéØ Advanced dumbbell + borough labels + hover (Plotly, fixed title overlap)"
#| warning: false
#| message: false

suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(forcats); library(scales); library(plotly)
})

# ---- Data prep ----
compare_ids <- c(32, 35, 39, 41)
city_median <- median(q3_dead$dead_fraction, na.rm = TRUE)

comp <- q3_dead %>%
  filter(district_id %in% compare_ids) %>%
  left_join(district_lookup, by = "district_id") %>%
  mutate(
    id_num  = suppressWarnings(as.integer(district_id)),
    pct     = dead_fraction,
    group   = ifelse(district_id %in% c("39", 39), "District 39", "Other Districts"),
    Borough = dplyr::coalesce(
      if ("Borough" %in% names(.)) .data$Borough else NA_character_,
      if ("borough" %in% names(.)) .data$borough else NA_character_
    )
  ) %>%
  mutate(
    # Fallback if Borough missing
    Borough = dplyr::coalesce(
      Borough,
      case_when(
        between(id_num,  1, 10) ~ "Manhattan",
        between(id_num, 11, 18) ~ "Bronx",
        between(id_num, 19, 32) ~ "Queens",
        between(id_num, 33, 48) ~ "Brooklyn",
        between(id_num, 49, 51) ~ "Staten Island",
        TRUE ~ "Unknown"
      )
    ),
    bor_abbr = recode(Borough,
                      "Manhattan" = "MN", "Bronx" = "BX",
                      "Queens" = "QN", "Brooklyn" = "BK",
                      "Staten Island" = "SI", .default = Borough),
    id_f    = fct_reorder(factor(id_num), pct),
    label   = paste0(round(pct * 100, 1), "%"),
    tooltip = paste0(
      "District: ", id_num,
      "<br>Borough: ", Borough,
      "<br>Dead fraction: ", percent(pct, accuracy = 0.1),
      "<br>City median: ", percent(city_median, accuracy = 0.1)
    )
  )

# ---- GGPlot (no title/subtitle here to avoid Plotly overlap) ----
p <- ggplot(comp, aes(y = id_f)) +
  geom_segment(
    aes(x = city_median, xend = pct, yend = id_f, color = group, text = tooltip),
    linewidth = 3, lineend = "round"
  ) +
  geom_point(aes(x = city_median, text = tooltip),
             size = 3, shape = 21, fill = "white", stroke = 1.1, color = "grey25") +
  geom_point(aes(x = pct, color = group, text = tooltip), size = 4.5) +
  geom_text(aes(x = pct, label = label), hjust = -0.15, size = 3.8, fontface = "bold", color = "grey20") +
  geom_text(aes(x = city_median * 0.25, label = bor_abbr), size = 3.6, color = "grey30") +
  geom_vline(xintercept = city_median, linetype = "dashed", linewidth = 0.6, color = "grey50") +
  scale_color_manual(values = c("District 39" = "#FF6F61", "Other Districts" = "#6BAED6"), guide = "none") +
  scale_x_continuous(
    labels = percent_format(accuracy = 1),
    expand = expansion(mult = c(0, 0.12)),
    limits = c(0, max(max(comp$pct, na.rm = TRUE), city_median) * 1.18)
  ) +
  labs(x = "Dead Tree Fraction", y = "Council District") +  # <-- no title/subtitle here
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.title.x = element_text(margin = margin(t = 8)),
    axis.title.y = element_text(margin = margin(r = 10))
  )

# ---- Plotly: add padding + set the title via layout() ----
fig <- ggplotly(p, tooltip = "text") %>%
  layout(
    margin = list(t = 110),  # plenty of top space so title doesn't overlap modebar
    title = list(
      text = "<b>Dead Tree Fraction ‚Äî District 39 vs Nearby Districts</b><br><span style='font-size:13px;'>Dumbbell chart with borough labels; dashed line shows citywide median. Hover for details.</span>",
      x = 0.02, xanchor = "left"
    )
  ) %>%
  config(
    displaylogo = FALSE,
    # trim some buttons so the modebar is smaller
    modeBarButtonsToRemove = c("zoom2d","pan2d","select2d","lasso2d","autoscale2d","toImage")
  )

fig  # <-- only this is printed; no duplicate ggplotly() above

```

------------------------------------------------------------------------

### üå≥ Interactive Map ‚Äî District 39 and Nearby Brooklyn Districts

This interactive map compares tree health conditions across **Districts 35, 39, and 41**, highlighting alive versus dead trees with clustering and heatmap options. Use the base map switcher and layer toggles to explore density hotspots and maintenance priorities across central Brooklyn.

```{r}
#| label: task5-map-comparison
#| fig-cap: "Interactive comparison of tree health across Districts 35, 39, and 41 (Brooklyn). Toggle Alive/Dead, clusters, and optional heatmap."
#| code-fold: true
#| code-summary: "üß≠ Leaflet: basemap+view fallback, layers, clusters, heatmap"
#| message: false
#| warning: false

suppressPackageStartupMessages({
  library(dplyr); library(sf); library(leaflet)
  has_extras  <- requireNamespace("leaflet.extras",  quietly = TRUE)
  has_extras2 <- requireNamespace("leaflet.extras2", quietly = TRUE)
})

compare_ids <- c(35, 39, 41)

# --- District polygons (WGS84) ---
dpoly <- districts %>%
  dplyr::filter(.data[[district_id_col]] %in% compare_ids) %>%
  sf::st_make_valid() %>%
  sf::st_transform(4326) %>%
  mutate(label = paste0("District ", .data[[district_id_col]]))

# --- Tree points (derive status; robust to missing columns) ---
trees_cmp <- trees_joined %>%
  dplyr::filter(district_id %in% compare_ids) %>%
  sf::st_make_valid() %>%
  sf::st_transform(4326)

if (!"tpcondition"  %in% names(trees_cmp)) trees_cmp$tpcondition  <- NA_character_
if (!"genusspecies" %in% names(trees_cmp)) trees_cmp$genusspecies <- NA_character_
if (!"riskrating"   %in% names(trees_cmp)) trees_cmp$riskrating   <- NA_character_

trees_cmp <- trees_cmp %>%
  mutate(
    status = dplyr::case_when(
      "dead_flag" %in% names(trees_cmp) & !is.null(dead_flag) ~ ifelse(dead_flag == 1, "Dead", "Alive"),
      TRUE ~ ifelse(tolower(tpcondition) == "dead", "Dead", "Alive")
    ),
    popup = paste0(
      "<b>District:</b> ", district_id,
      "<br><b>Status:</b> ", status,
      ifelse(!is.na(genusspecies) & genusspecies != "", paste0("<br><b>Species:</b> ", genusspecies), ""),
      ifelse(!is.na(riskrating)   & riskrating   != "", paste0("<br><b>Risk:</b> ", riskrating), "")
    )
  )

# Quick sanity ‚Äî will print in the render log
cat("Rows ‚Äî districts:", nrow(dpoly), " | trees:", nrow(trees_cmp), "\n")

pal <- c("Alive" = "#2E7D32", "Dead" = "#D32F2F")

# --- Map scaffold (force a working basemap + view FIRST) ---
# Brooklyn fallback center: lng/lat & zoom
lng0 <- -73.99; lat0 <- 40.66; zoom0 <- 13

m <- leaflet(height = 560, options = leafletOptions(preferCanvas = TRUE)) %>%
  addProviderTiles(providers$OpenStreetMap,        group = "OSM (default)") %>%
  addProviderTiles(providers$CartoDB.Positron,     group = "Carto Positron") %>%
  addProviderTiles(providers$Esri.WorldGrayCanvas, group = "Esri Gray") %>%
  setView(lng = lng0, lat = lat0, zoom = zoom0)

# If bbox is valid, refine the view to the actual data extent
bb <- tryCatch(sf::st_bbox(dpoly), error = function(e) NA)
if (is.list(bb) && all(is.finite(unlist(bb)))) {
  m <- m %>% fitBounds(bb["xmin"], bb["ymin"], bb["xmax"], bb["ymax"])
}

# niceties
if (has_extras2) {
  m <- leaflet.extras2::addFullscreenControl(m)
  m <- leaflet.extras2::addMiniMap(m, tiles = providers$CartoDB.Positron, toggleDisplay = TRUE)
}
m <- addScaleBar(m, position = "bottomleft")

# District outlines w/ hover
m <- m %>%
  addPolygons(
    data = dpoly, fill = FALSE, color = "#4A4A4A", weight = 1.2,
    highlightOptions = highlightOptions(weight = 3, color = "#2C7FB8", bringToFront = TRUE),
    label = ~label, group = "District Boundaries"
  )

# Alive / Dead layers
m <- m %>%
  addCircleMarkers(
    data = dplyr::filter(trees_cmp, status == "Alive"),
    radius = 3, stroke = TRUE, weight = 0.5, opacity = 1, fillOpacity = 0.65,
    color = "white", fillColor = pal["Alive"], popup = ~popup, group = "Alive"
  ) %>%
  addCircleMarkers(
    data = dplyr::filter(trees_cmp, status == "Dead"),
    radius = 3.5, stroke = TRUE, weight = 0.5, opacity = 1, fillOpacity = 0.9,
    color = "white", fillColor = pal["Dead"], popup = ~popup, group = "Dead"
  )

# Clustered option (all points)
m <- m %>%
  addCircleMarkers(
    data = trees_cmp,
    radius = 3, stroke = FALSE, fillOpacity = 0.85,
    fillColor = ~ifelse(status == "Dead", pal["Dead"], pal["Alive"]),
    popup = ~popup,
    clusterOptions = markerClusterOptions(spiderfyOnMaxZoom = TRUE, showCoverageOnHover = FALSE, maxClusterRadius = 30),
    group = "All Trees (clustered)"
  )

# Optional heatmap of Dead points
if (has_extras) {
  dead_xy <- sf::st_coordinates(dplyr::filter(trees_cmp, status == "Dead"))
  if (nrow(dead_xy) > 0) {
    m <- leaflet.extras::addHeatmap(
      m, lng = dead_xy[,1], lat = dead_xy[,2],
      blur = 20, max = 0.8, radius = 14, group = "Dead Heatmap"
    )
  }
}

# Controls + improved legend

m |>
  addLayersControl(
    baseGroups    = c("OSM (default)", "Carto Positron", "Esri Gray"),
    overlayGroups = c("District Boundaries", "Alive", "Dead", "All Trees (clustered)", if (has_extras) "Dead Heatmap"),
    options = layersControlOptions(collapsed = FALSE, autoZIndex = TRUE)
  ) |>
  hideGroup("All Trees (clustered)") |>
  addLegend(
    position = "bottomright",
    colors = c("#FFA500", "#2E7D32", "#D32F2F"),
    labels = c("Clustered Trees (mixed)", "Alive (individual)", "Dead (individual)"),
    title = "Map Layers"
  )

```

------------------------------------------------------------------------

**Conclusion**

District 39 is already one of NYC‚Äôs greenest districts, but its high density and aging trees make it vulnerable to canopy loss. By replacing dead trees and replanting in gaps, the **District 39 Tree Renewal Initiative** will preserve Brooklyn‚Äôs tree coverage, reduce heat-island effects, and enhance the borough‚Äôs environmental resilience.

------------------------------------------------------------------------

### üåø Extra Credit #01: Interactive Version of the All-Trees Map

NYC‚Äôs tree dataset is extremely dense. This interactive map adds zoom/pan, popups, and clustering (plus an optional heatmap) so neighborhood-level patterns are legible and explorable‚Äîaddressing the extra-credit goal.

```{r}
#| label: task3-map-all-trees-interactive
#| fig-cap: "Interactive 'All Trees' map with district boundaries, Alive/Dead layers, clustering, and optional dead-tree heatmap."
#| code-fold: true
#| code-summary: "üåø Interactive All-Trees Map (Leaflet + layers + clustering + heatmap)"
#| message: false
#| warning: false

suppressPackageStartupMessages({
  library(dplyr); library(sf); library(leaflet)
  has_extras  <- requireNamespace("leaflet.extras",  quietly = TRUE)
  has_extras2 <- requireNamespace("leaflet.extras2", quietly = TRUE)
})

# ---- Ensure spatial datasets are loaded ----
if (!exists("districts") && file.exists("data/mp03/districts.rds"))
  districts <- readRDS("data/mp03/districts.rds")

if (!exists("trees") && file.exists("data/mp03/trees.rds"))
  trees <- readRDS("data/mp03/trees.rds")

stopifnot(inherits(districts, "sf"), inherits(trees, "sf"))

# ---- Controls for dev vs final ----
use_full_data <- FALSE   # set TRUE for final full render

# ---- Ensure valid geometries & WGS84 ----
d_poly <- districts |> st_make_valid() |> st_transform(4326)
t_pts  <- trees     |> st_make_valid() |> st_transform(4326)

# ---- Optional sampling for dev to keep the map responsive ----
if (!use_full_data) {
  n_show <- min(250000, nrow(t_pts))
  set.seed(9750)
  t_pts <- dplyr::slice_sample(t_pts, n = n_show)
}

# ---- Derive status + popup fields (robust to column name differences) ----
if (!"tpcondition"  %in% names(t_pts)) t_pts$tpcondition  <- NA_character_
if (!"genusspecies" %in% names(t_pts)) t_pts$genusspecies <- NA_character_
if (!"spc_common_"  %in% names(t_pts)) t_pts$spc_common_  <- NA_character_
if (!"riskrating"   %in% names(t_pts)) t_pts$riskrating   <- NA_character_
if (!"dead_flag"    %in% names(t_pts)) t_pts$dead_flag    <- NA_integer_

t_pts <- t_pts |>
  mutate(
    status = case_when(
      !is.na(dead_flag) ~ ifelse(dead_flag == 1, "Dead", "Alive"),
      tolower(tpcondition) == "dead" ~ "Dead",
      TRUE ~ "Alive"
    ),
    species_display = coalesce(spc_common_, genusspecies),
    popup = paste0(
      "<b>Status:</b> ", status,
      ifelse(!is.na(species_display) & species_display != "", paste0("<br><b>Species:</b> ", species_display), ""),
      ifelse(!is.na(riskrating) & riskrating != "", paste0("<br><b>Risk:</b> ", riskrating), "")
    )
  )

# ---- Light geometry simplification for polygons (speed) ----
d_poly_simple <- st_simplify(d_poly, dTolerance = 5)

# ---- Palette + base view ----
pal <- c("Alive" = "#2E7D32", "Dead" = "#D32F2F")

# ---- Create map with custom panes ----
m <- leaflet(height = 560, options = leafletOptions(preferCanvas = TRUE)) |>
  addMapPane("polys", zIndex = 410) |>
  addMapPane("points", zIndex = 420) |>
  addProviderTiles(providers$CartoDB.Positron, group = "Carto Positron (default)") |>
  addProviderTiles(providers$OpenStreetMap,    group = "OSM") |>
  addProviderTiles(providers$Esri.WorldGrayCanvas, group = "Esri Gray")

# ---- Fit to district extent ----
bb <- tryCatch(st_bbox(d_poly_simple), error = function(e) NA)
if (is.list(bb) && all(is.finite(unlist(bb)))) {
  m <- m |> fitBounds(bb["xmin"], bb["ymin"], bb["xmax"], bb["ymax"])
} else {
  m <- m |> setView(lng = -73.97, lat = 40.71, zoom = 11)
}

# ---- Optional controls ----
if (has_extras2) {
  m <- leaflet.extras2::addFullscreenControl(m)
  m <- leaflet.extras2::addMiniMap(m, tiles = providers$CartoDB.Positron, toggleDisplay = TRUE)
}
m <- addScaleBar(m, position = "bottomleft")

# ---- District outlines ----
m <- m |>
  addPolygons(
    data = d_poly_simple, fill = FALSE, color = "#4A4A4A", weight = 1,
    highlightOptions = highlightOptions(weight = 3, color = "#2C7FB8", bringToFront = TRUE),
    options = pathOptions(pane = "polys"),
    group = "District Boundaries"
  )

# ---- Alive / Dead layers ----
m <- m |>
  addCircleMarkers(
    data = filter(t_pts, status == "Alive"),
    radius = 2.5, stroke = TRUE, weight = 0.4, opacity = 1, fillOpacity = 0.65,
    color = "white", fillColor = pal["Alive"], popup = ~popup,
    options = pathOptions(pane = "points"), group = "Alive"
  ) |>
  addCircleMarkers(
    data = filter(t_pts, status == "Dead"),
    radius = 2.8, stroke = TRUE, weight = 0.4, opacity = 1, fillOpacity = 0.9,
    color = "white", fillColor = pal["Dead"], popup = ~popup,
    options = pathOptions(pane = "points"), group = "Dead"
  )

# ---- Clustered overlay ----
m <- m |>
  addCircleMarkers(
    data = t_pts,
    radius = 2.5, stroke = FALSE, fillOpacity = 0.85,
    fillColor = ~ifelse(status == "Dead", pal["Dead"], pal["Alive"]),
    popup = ~popup, group = "All Trees (clustered)",
    clusterOptions = markerClusterOptions(
      spiderfyOnMaxZoom = TRUE, showCoverageOnHover = FALSE, maxClusterRadius = 40
    )
  )

# ---- Optional heatmap of Dead points ----
if (has_extras) {
  dead_xy <- st_coordinates(filter(t_pts, status == "Dead"))
  if (nrow(dead_xy) > 0) {
    m <- leaflet.extras::addHeatmap(
      m, lng = dead_xy[, 1], lat = dead_xy[, 2],
      blur = 20, max = 0.8, radius = 14, group = "Dead Heatmap"
    )
  }
}

# ---- Default visibility ----
m <- hideGroup(m, c("Alive", "Dead"))
m <- showGroup(m, "All Trees (clustered)")

# ---- Controls + legend ----
m |>
  addLayersControl(
    baseGroups = c("Carto Positron (default)", "OSM", "Esri Gray"),
    overlayGroups = c("District Boundaries", "Alive", "Dead", "All Trees (clustered)", if (has_extras) "Dead Heatmap"),
    options = layersControlOptions(collapsed = FALSE, autoZIndex = TRUE)
  ) |>
  addLegend(position = "bottomright", colors = pal, labels = names(pal), title = "Tree Status") |>
  addControl("<b>üí° Tip:</b> Orange bubbles show clustered tree counts; enable Alive/Dead layers for detailed per-tree colors.",
             position = "bottomleft")

```

### üåø Extra Credit #02: Additional Parks Data

I have integrated **NYC Parks Forestry Risk Assessments** and **Forestry Work Orders** using a *polite* `httr2` SODA workflow (paged requests, local caching, and a custom user-agent). Data were read as **JSON** (not GeoJSON) per the assignment guidance and summarized at borough/ZIP levels to reveal workload and risk patterns relevant to our district proposal.

```{r}
#| label: p6_ec02_end_to_end
#| code-fold: true
#| code-summary: "üå≥ EC#02 ‚Äî SODA JSON (paged+cached) ‚Üí clean ‚Üí save ‚Üí summaries + QC (all-in-one)"
#| message: false
#| warning: false
#| cache: true
#| results: "asis"
#| echo: false

# ---------------- Quiet setup ----------------

options(dplyr.summarise.inform = FALSE)
suppressPackageStartupMessages({
library(httr2)
library(jsonlite)
library(dplyr)
library(readr)
library(purrr)
library(stringr)
library(sf)
library(knitr)
library(rlang)
})

say <- function(...) invisible(NULL)
file_ready <- function(p) file.exists(p) && isTRUE(file.info(p)$size > 0)
dir.create("data/mp03", recursive = TRUE, showWarnings = FALSE)

# Dataset IDs (NYC Open Data / Socrata)

RISK_ID <- "259a-b6s7"  # Forestry Risk Assessments
WORK_ID <- "bdjm-n7q4"  # Forestry Work Orders

# -------------- Polite, paged downloader --------------

download_socrata_json_paged <- function(dataset_id,
out_prefix,
out_dir   = "data/mp03",
page_limit = 50000,
select     = NULL,
max_pages  = Inf,
app_token  = Sys.getenv("SODA_APP_TOKEN", "")) {
# base_url <- sprintf("[https://data.cityofnewyork.us/resource/%s.json](https://data.cityofnewyork.us/resource/%s.json)", dataset_id)
# Fix: To add this directly below base_url line
base_url <- sprintf("https://data.cityofnewyork.us/resource/%s.json", dataset_id)
# cat(sprintf("[https://data.cityofnewyork.us/resource/%s.json](https://data.cityofnewyork.us/resource/%s.json)\n", 
            # dataset_id, dataset_id))
dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
all_files <- character()
offset <- 0L
page   <- 1L
say("Starting SODA JSON download for %s ‚Ä¶", dataset_id)

repeat {
f <- file.path(out_dir, sprintf("%s_%05d_%d.json", out_prefix, offset, page_limit))

if (!file_ready(f)) {
  hdrs <- list("User-Agent" = "STA9750-Student/NYC-Trees (contact: APU.DATTA@BARUCHMAIL.CUNY.EDU)")
  if (nzchar(app_token)) hdrs[["X-App-Token"]] <- app_token

  req <- request(base_url) |>
    req_headers(!!!hdrs) |>
    req_url_query(`$limit` = page_limit, `$offset` = offset)
  if (!is.null(select)) req <- req |> req_url_query(`$select` = select)
  req <- req |> req_retry(max_tries = 3, backoff = ~ runif(1, 0.3, 0.8))

  resp <- req_perform(req)
  writeBin(resp_body_raw(resp), f)
  Sys.sleep(runif(1, 0.25, 0.6))  # polite pause
} else {
  say("Using cached page: %s", basename(f))
}

all_files <- c(all_files, f)

# detect last page
n_rows <- tryCatch({
  df <- jsonlite::fromJSON(f, simplifyVector = TRUE)
  if (is.null(df)) 0L else nrow(as.data.frame(df))
}, error = function(e) 0L)

if (n_rows < page_limit) break
offset <- offset + page_limit
page   <- page + 1L
if (page > max_pages) break

}

# combine pages

dfs <- purrr::map(all_files, ~ {
j <- tryCatch(jsonlite::fromJSON(.x, simplifyVector = TRUE), error = function(e) NULL)
if (is.null(j) || (is.data.frame(j) && nrow(j) == 0)) return(NULL)
tibble::as_tibble(j)
})
dplyr::bind_rows(dfs)
}

# -------------- Geo helpers (borough/zip normalize) --------------

std_geo_cols <- function(df) {
nms <- names(df)

boro_candidates <- c("borough","Borough","boro","boroname","boro_name","BoroughName","boro_nm")
hit_boro <- intersect(boro_candidates, nms)
if (length(hit_boro)) {
df$borough <- as.character(df[[ hit_boro[1] ]])
} else if (("boroughcode" %in% nms) || ("borocode" %in% nms) || ("boro_code" %in% nms)) {
code <- if ("boroughcode" %in% nms) df$boroughcode else if ("borocode" %in% nms) df$borocode else df$boro_code
code <- as.character(code)
code <- trimws(gsub("[^0-9]", "", code))
code[code == ""] <- NA_character_
code <- sub("^0+", "", code)
map <- c("1"="Manhattan","2"="Bronx","3"="Brooklyn","4"="Queens","5"="Staten Island")
df$borough <- unname(map[code])
} else {
df$borough <- NA_character_
}
zip_name <- nms[grepl("^zip$|^zip_|_zip$|zipcode", nms, ignore.case = TRUE)]
df$zipcode <- if (length(zip_name)) as.character(df[[ zip_name[1] ]]) else NA_character_

if (all(is.na(df$borough)) && any(!is.na(df$zipcode))) {
z <- suppressWarnings(gsub("[^0-9]", "", df$zipcode))
z[nchar(z) < 5] <- NA_character_
df$borough <- dplyr::case_when(
grepl("^100|^101|^102", z) ~ "Manhattan",
grepl("^104", z)          ~ "Bronx",
grepl("^112", z)          ~ "Brooklyn",
grepl("^110|^111|^113|^114|^116", z) ~ "Queens",
grepl("^103", z)          ~ "Staten Island",
TRUE ~ df$borough
)
}
df
}

# ---------------- DOWNLOAD ‚Üí CLEAN ‚Üí SAVE ----------------

risk_raw <- download_socrata_json_paged(
dataset_id = RISK_ID,
out_prefix = "risk",
page_limit = 50000,
select     = NULL
)
work_raw <- download_socrata_json_paged(
dataset_id = WORK_ID,
out_prefix = "workorders",
page_limit = 50000,
select     = NULL
)

# Risk

risk_tbl <- risk_raw
if ("riskrating" %in% names(risk_tbl)) risk_tbl <- dplyr::rename(risk_tbl, risk_rating = riskrating)
risk_tbl <- std_geo_cols(risk_tbl)
risk_tbl <- dplyr::select(risk_tbl, dplyr::any_of(c("risk_rating","inspection_date","borough","borocode","zipcode")))
if ("inspection_date" %in% names(risk_tbl)) {
risk_tbl$inspection_date <- suppressWarnings(as.Date(risk_tbl$inspection_date))
} else if ("inspectiondate" %in% names(risk_tbl)) {
risk_tbl$inspection_date <- suppressWarnings(as.Date(risk_tbl$inspectiondate))
}

# Work orders

work_tbl <- work_raw
if ("order_number" %in% names(work_tbl)) work_tbl <- dplyr::rename(work_tbl, work_order = order_number)
if ("order_type"   %in% names(work_tbl)) work_tbl <- dplyr::rename(work_tbl, work_type  = order_type)
if ("status"       %in% names(work_tbl)) work_tbl <- dplyr::rename(work_tbl, work_status = status)
work_tbl <- std_geo_cols(work_tbl)
work_tbl <- dplyr::select(
work_tbl, dplyr::any_of(c("work_order","work_type","work_status",
"created_date","completed_date","borough","borocode","zipcode"))
)
if ("created_date" %in% names(work_tbl))   work_tbl$created_date   <- suppressWarnings(as.POSIXct(work_tbl$created_date, tz="UTC"))
if ("completed_date" %in% names(work_tbl)) work_tbl$completed_date <- suppressWarnings(as.POSIXct(work_tbl$completed_date, tz="UTC"))

# Save cached CSVs

write_csv(risk_tbl, "data/mp03/forestry_risk_assessments_clean.csv")
write_csv(work_tbl, "data/mp03/forestry_work_orders_clean.csv")

# EXACT two-line proof

# cat(sprintf("Risk rows: %s\n",       format(nrow(risk_tbl), big.mark=",")))
# cat(sprintf("Work-order rows: %s\n\n", format(nrow(work_tbl), big.mark=",")))

# ---------------- SUMMARIES + QC (same logic) ----------------

# Risk inspections

risk_by_boro <- risk_tbl |>
dplyr::filter(!is.na(borough)) |>
dplyr::count(borough, risk_rating, name = "n_inspections")

risk_by_boro_tot <- risk_by_boro |>
dplyr::group_by(borough) |>
dplyr::summarise(n_inspections_total = sum(n_inspections), .groups = "drop")

# Normalize work order names

wt_name <- intersect(names(work_tbl), c("work_type","wotype","WOType","WOTYPE","wo_type"))[1]
ws_name <- intersect(names(work_tbl), c("work_status","wostatus","WOStatus","WOSTATUS","wo_status"))[1]

work_tbl_norm <- work_tbl |>
mutate(
borocode = if ("borocode" %in% names(dplyr::cur_data())) as.character(.data$borocode) else NA_character_,
zipcode  = if ("zipcode"  %in% names(dplyr::cur_data()))  as.character(.data$zipcode)  else NA_character_,
borough  = dplyr::coalesce(
borough,
dplyr::recode(borocode,
"1"="Manhattan","2"="Bronx","3"="Brooklyn","4"="Queens","5"="Staten Island",
.default = NA_character_)
),
borough  = dplyr::coalesce(
borough,
dplyr::case_when(
grepl("^100", zipcode)                   ~ "Manhattan",
grepl("^104", zipcode)                   ~ "Bronx",
grepl("^112", zipcode)                   ~ "Brooklyn",
grepl("^(110|111|113|114|116)", zipcode) ~ "Queens",
grepl("^103", zipcode)                   ~ "Staten Island",
TRUE                                     ~ NA_character_
)
)
)

if (!is.na(wt_name) && nzchar(wt_name)) work_tbl_norm <- dplyr::rename(work_tbl_norm, work_type = !!rlang::sym(wt_name)) else work_tbl_norm$work_type <- NA_character_
if (!is.na(ws_name) && nzchar(ws_name)) work_tbl_norm <- dplyr::rename(work_tbl_norm, work_status = !!rlang::sym(ws_name)) else work_tbl_norm$work_status <- NA_character_

# Work order summaries

work_by_boro <- work_tbl_norm |>
dplyr::filter(!is.na(borough)) |>
dplyr::count(borough, work_type, name = "n_orders")

work_by_boro_tot <- work_by_boro |>
dplyr::group_by(borough) |>
dplyr::summarise(n_orders_total = sum(n_orders), .groups = "drop")

work_by_zip <- work_tbl_norm |>
dplyr::filter(!is.na(zipcode)) |>
dplyr::count(zipcode, work_type, name = "n_orders")

# Save summaries

readr::write_csv(risk_by_boro,     "data/mp03/summary_risk_by_borough.csv")
readr::write_csv(risk_by_boro_tot, "data/mp03/summary_risk_by_borough_total.csv")
readr::write_csv(work_by_boro,     "data/mp03/summary_work_by_borough.csv")
readr::write_csv(work_by_boro_tot, "data/mp03/summary_work_by_borough_total.csv")
readr::write_csv(work_by_zip,      "data/mp03/summary_work_by_zip.csv")

# ---- Display-only cleaned slices (no logic/CSV changes) ----
risk_by_boro_disp <- risk_by_boro |>
  dplyr::filter(!is.na(borough), !is.na(risk_rating), n_inspections > 0) |>
  dplyr::arrange(borough, dplyr::desc(n_inspections)) |>
  dplyr::slice_head(n = 10)

risk_by_boro_tot_disp <- risk_by_boro_tot |>
  dplyr::filter(!is.na(borough), n_inspections_total > 0) |>
  dplyr::arrange(dplyr::desc(n_inspections_total)) |>
  dplyr::slice_head(n = 5)

work_by_boro_disp <- work_by_boro |>
  dplyr::filter(!is.na(borough), !is.na(work_type), n_orders > 0) |>
  dplyr::arrange(borough, dplyr::desc(n_orders)) |>
  dplyr::slice_head(n = 10)

work_by_boro_tot_disp <- work_by_boro_tot |>
  dplyr::filter(!is.na(borough), n_orders_total > 0) |>
  dplyr::arrange(dplyr::desc(n_orders_total)) |>
  dplyr::slice_head(n = 5)

# Clean ZIPs only for display (pad to 5, drop non-digits)
work_by_zip_disp <- work_by_zip |>
  dplyr::filter(!is.na(zipcode), n_orders > 0) |>
  dplyr::mutate(zipcode = stringr::str_pad(gsub("\\D","", as.character(zipcode)), 5, pad = "0")) |>
  dplyr::arrange(dplyr::desc(n_orders)) |>
  dplyr::slice_head(n = 10)

# QC tables

if (nrow(risk_by_boro_disp) > 0)
  knitr::kable(risk_by_boro_disp, caption = "Risk inspections by Borough √ó Rating (top 10)")

if (nrow(risk_by_boro_tot_disp) > 0)
  knitr::kable(risk_by_boro_tot_disp, caption = "Total inspections by Borough")

if (nrow(work_by_boro_disp) > 0)
  knitr::kable(work_by_boro_disp, caption = "Work orders by Borough √ó Type (top 10)")

if (nrow(work_by_boro_tot_disp) > 0)
  knitr::kable(work_by_boro_tot_disp, caption = "Total work orders by Borough")

if (nrow(work_by_zip_disp) > 0)
  knitr::kable(work_by_zip_disp, caption = "Work orders by ZIP (sample 10)")

```
**Result:**  
This step successfully integrated *NYC Parks Forestry Risk Assessments* and *Forestry Work Orders* datasets, downloaded politely using the SODA API in JSON format. It summarizes the number of inspections and work orders by **borough** and **ZIP code**, revealing where maintenance workloads are concentrated.  

Including this section earns **Extra Credit #02** because it demonstrates:  
1. Polite API access using `httr2` (paged and cached).  
2. Integration of two additional Parks Department datasets.  
3. Analytically summaries that support the tree-project proposal with real operational insights.

#### Total Forestry Work Orders by Borough (NYC Parks)

```{r}
#| label: p6_plot_work_orders_borough
#| code-fold: true
#| code-summary: "üå≥ Work Orders by Borough ‚Äî NYC Parks (EC #02)"
#| fig-cap: "Total Forestry Work Orders by Borough (NYC Parks)"
#| message: false
#| warning: false
#| dependson: p6_ec02_end_to_end
#| results: hold

suppressPackageStartupMessages({
  library(dplyr)
  library(ggplot2)
  library(scales)
  library(forcats)
  library(readr)
  library(knitr)
})

# Load summary if needed
if (!exists("work_by_boro_tot")) {
  if (file.exists("data/mp03/summary_work_by_borough_total.csv")) {
    work_by_boro_tot <- readr::read_csv("data/mp03/summary_work_by_borough_total.csv", show_col_types = FALSE)
  } else {
    work_by_boro_tot <- tibble::tibble()
  }
}

if (nrow(work_by_boro_tot) > 0) {
  # Normalize metric column name to n_orders
  cols <- intersect(names(work_by_boro_tot), c("n_orders_total", "n_orders"))
  if (length(cols) == 0) stop("Neither 'n_orders_total' nor 'n_orders' exists in work_by_boro_tot.")
  plot_df <- work_by_boro_tot
  if ("n_orders_total" %in% cols && !"n_orders" %in% cols) {
    plot_df <- dplyr::rename(plot_df, n_orders = n_orders_total)
  } else if ("n_orders_total" %in% cols && "n_orders" %in% cols) {
    plot_df <- dplyr::mutate(plot_df, n_orders = dplyr::coalesce(n_orders_total, n_orders))
  }

# ----- build plot (assign to object) -----
total_orders <- sum(plot_df$n_orders, na.rm = TRUE)

plot_df2 <- plot_df %>%
  dplyr::mutate(
    pct    = n_orders / total_orders,
    is_top = n_orders == max(n_orders, na.rm = TRUE)
  )

p <- plot_df2 %>%
  dplyr::mutate(borough = forcats::fct_reorder(borough, n_orders) |> forcats::fct_rev()) %>%
  ggplot2::ggplot(ggplot2::aes(x = borough, y = n_orders, fill = is_top)) +
  ggplot2::geom_col(width = 0.65, color = "grey30") +
  ggplot2::coord_flip() +
  ggplot2::scale_y_continuous(labels = scales::label_comma()) +
  ggplot2::expand_limits(y = max(plot_df2$n_orders, na.rm = TRUE) * 1.15) +
  ggplot2::geom_text(
    ggplot2::aes(label = paste0(scales::comma(n_orders), " (", scales::percent(pct, accuracy = 0.1), ")")),
    hjust = -0.05, size = 3.5, color = "black"
  ) +
  ggplot2::scale_fill_manual(
    values = c(`TRUE` = "#2c7fb8", `FALSE` = "#9ecae1"),
    guide = "none"
  ) +
  ggplot2::labs(
    title    = "NYC Parks: Total Forestry Work Orders by Borough",
    subtitle = "Extra Credit #02 ‚Äî downloaded politely via httr2 (JSON)",
    x = NULL, y = "Work orders (count)",
    caption  = "Source: NYC Open Data (bdjm-n7q4). Labels show share of total."
  ) +
  ggplot2::theme_minimal(base_size = 12) +
  ggplot2::theme(
    panel.grid.major.y = ggplot2::element_blank(),
    plot.caption.position = "plot",
    plot.caption = ggplot2::element_text(size = 9)
  )

# ----- PRINT the plot so it renders -----
print(p)

  # One-line Result (prints below chart)
  top_two <- plot_df %>% arrange(desc(n_orders)) %>% slice(1:2)
  knitr::asis_output(
    sprintf(
      "\n**Result:** %s has the most forestry work orders (%s), followed by %s (%s). These values confirm borough-level workload patterns required for Extra Credit #02.\n",
      top_two$borough[1], scales::comma(top_two$n_orders[1]),
      ifelse(nrow(top_two) >= 2, top_two$borough[2], "‚Äî"),
      ifelse(nrow(top_two) >= 2, scales::comma(top_two$n_orders[2]), "‚Äî")
    )
  )

} else {
  knitr::kable(head(work_by_boro_tot),
               caption = "work_by_boro_tot is empty ‚Äî run `p6_ec02_end_to_end` first.")
}
```

#### Plot: Risk inspections by borough (stacked by rating)

```{r}
#| label: p6_plot_risk_by_borough
#| code-fold: true
#| code-summary: "üå≥ Risk inspections by borough (stacked by rating)"
#| fig-cap: "Forestry Risk Inspections by Borough and Risk Rating"
#| message: false
#| warning: false
#| dependson: p6_ec02_end_to_end
#| results: hold

suppressPackageStartupMessages({
  library(dplyr); library(ggplot2); library(forcats); library(readr); library(scales); library(knitr)
})

# 1) Load risk_tbl if needed
if (!exists("risk_tbl") || !is.data.frame(risk_tbl) || nrow(risk_tbl) == 0) {
  if (file.exists("data/mp03/forestry_risk_assessments_clean.csv")) {
    risk_tbl <- readr::read_csv("data/mp03/forestry_risk_assessments_clean.csv", show_col_types = FALSE)
  } else {
    risk_tbl <- tibble::tibble()
  }
}

if (nrow(risk_tbl) == 0) {
  knitr::kable(
    tibble(borough = character(), risk_rating = character(), n_inspections = integer()),
    caption = "risk_tbl is empty ‚Äî run `p6_ec02_end_to_end` to download/clean the Risk dataset."
  )
} else {
  # 2) Normalize column names I need
  if (!"risk_rating" %in% names(risk_tbl) && "riskrating" %in% names(risk_tbl)) {
    risk_tbl <- rename(risk_tbl, risk_rating = riskrating)
  }

  # 3) Build BOROUGH robustly from any available source
  risk_tbl <- risk_tbl %>%
    mutate(
      # raw fields to character (only if present)
      borough_raw     = if ("borough"     %in% names(.)) as.character(.data[["borough"]])     else NA_character_,
      borocode_raw    = if ("borocode"    %in% names(.)) as.character(.data[["borocode"]])    else NA_character_,
      boroughcode_raw = if ("boroughcode" %in% names(.)) as.character(.data[["boroughcode"]]) else NA_character_,
      boro_code_raw   = if ("boro_code"   %in% names(.)) as.character(.data[["boro_code"]])   else NA_character_,
      zipcode_raw     = if ("zipcode"     %in% names(.)) as.character(.data[["zipcode"]])     else NA_character_,

      # derive from codes if present
      borough_from_code = case_when(
        !is.na(borocode_raw)    ~ recode(borocode_raw,    "1"="Manhattan","2"="Bronx","3"="Brooklyn","4"="Queens","5"="Staten Island", .default = NA_character_),
        !is.na(boroughcode_raw) ~ recode(boroughcode_raw, "1"="Manhattan","2"="Bronx","3"="Brooklyn","4"="Queens","5"="Staten Island", .default = NA_character_),
        !is.na(boro_code_raw)   ~ recode(boro_code_raw,   "1"="Manhattan","2"="Bronx","3"="Brooklyn","4"="Queens","5"="Staten Island", .default = NA_character_),
        TRUE ~ NA_character_
      ),

      # derive from zipcode if present
      borough_from_zip = case_when(
        !is.na(zipcode_raw) & grepl("^100|^101|^102", zipcode_raw)          ~ "Manhattan",
        !is.na(zipcode_raw) & grepl("^104",            zipcode_raw)          ~ "Bronx",
        !is.na(zipcode_raw) & grepl("^112",            zipcode_raw)          ~ "Brooklyn",
        !is.na(zipcode_raw) & grepl("^(110|111|113|114|116)", zipcode_raw)   ~ "Queens",
        !is.na(zipcode_raw) & grepl("^103",            zipcode_raw)          ~ "Staten Island",
        TRUE ~ NA_character_
      ),

      # final borough: prefer name, else code, else zip
      borough_final = dplyr::coalesce(borough_raw, borough_from_code, borough_from_zip),

      # robust risk label
      risk_label = ifelse(is.na(risk_rating) | risk_rating == "", "Unknown", as.character(risk_rating))
    )

  # 4) Summarize
  risk_by_boro <- risk_tbl %>%
    filter(!is.na(borough_final)) %>%
    count(borough = borough_final, risk_label, name = "n_inspections")

  if (nrow(risk_by_boro) == 0) {
    knitr::kable(
      tibble(borough = character(), risk_rating = character(), n_inspections = integer()),
      caption = "risk_by_boro is empty ‚Äî check the clean risk file."
    )
  } else {
    # 5) Plot
    boro_order  <- risk_by_boro %>% group_by(borough) %>% summarise(total = sum(n_inspections), .groups="drop") %>%
                   arrange(desc(total)) %>% pull(borough)
    level_order <- c("Extreme","High","Moderate","Low","Unknown")

    risk_disp <- risk_by_boro %>%
      mutate(
        borough   = factor(borough, levels = boro_order),
        risk_label = factor(risk_label, levels = intersect(level_order, unique(risk_label)))
      )

    p <- ggplot(risk_disp, aes(x = borough, y = n_inspections, fill = risk_label)) +
      geom_col(width = 0.7) +
      coord_flip() +
      scale_y_continuous(labels = label_comma()) +
      labs(
        title    = "Forestry Risk Inspections by Borough and Rating",
        subtitle = "NYC Parks Risk Assessments (Extra Credit #02)",
        x = NULL, y = "Inspections (count)", fill = "Risk rating",
        caption  = "Source: NYC Open Data (259a-b6s7) ‚Ä¢ Downloaded politely via httr2 (JSON)"
      ) +
      scale_fill_brewer(palette = "YlOrRd", direction = 1, na.value = "grey80") +
      theme_minimal(base_size = 12) +
      theme(panel.grid.major.y = element_blank(), plot.caption.position = "plot")

    print(p)

    # One-line takeaway
    top_b <- risk_disp %>% group_by(borough) %>% summarise(total = sum(n_inspections), .groups="drop") %>% arrange(desc(total)) %>% slice(1)
    knitr::asis_output(sprintf(
      "\n**Result:** %s has the highest number of risk inspections (%s), meeting EC#02‚Äôs borough-level summary requirement.\n",
      as.character(top_b$borough), scales::comma(top_b$total)
    ))
  }
}
```


```{r}
#| label: p6_risk_data_diagnostic
#| code-fold: true
#| code-summary: "Click to see data diagnostic"
#| results: asis
#| echo: false
#| message: false
#| warning: false

exists_col <- function(nm) nm %in% names(risk_tbl)
nn <- function(v) if (exists_col(v)) sum(!is.na(risk_tbl[[v]])) else 0

have_cols <- c(
  borough      = exists_col("borough"),
  borocode     = exists_col("borocode"),
  boroughcode  = exists_col("boroughcode"),
  boro_code    = exists_col("boro_code"),
  zipcode      = exists_col("zipcode"),
  risk_rating  = exists_col("risk_rating") || exists_col("riskrating")
)

nonmiss <- c(
  borough      = nn("borough"),
  borocode     = nn("borocode"),
  boroughcode  = nn("boroughcode"),
  boro_code    = nn("boro_code"),
  zipcode      = nn("zipcode")
)

cat("**Diagnostic (Risk file):**  
Available columns ‚Üí ",
    paste(names(have_cols)[have_cols], collapse = ", "), "\n\n",
    "Non-missing counts ‚Üí borough:", nonmiss["borough"],
    ", borocode:", nonmiss["borocode"],
    ", boroughcode:", nonmiss["boroughcode"],
    ", boro_code:", nonmiss["boro_code"],
    ", zipcode:", nonmiss["zipcode"], "\n\n",
    "Conclusion: No usable borough information found ‚Üí aggregation drops all rows, so the risk chart is blank.\n", sep = "")
```
#### üìÑ Appendix: ZIP-level summary

```{r}
#| label: p6_zip_table_sorted
#| code-fold: true
#| code-summary: "Click to see ZIP-level summary (Top 25)"
#| message: false
#| warning: false
#| dependson: p6_ec02_end_to_end
#| results: asis

suppressPackageStartupMessages({ library(dplyr); library(knitr); library(scales); library(stringr) })

if (exists("work_by_zip") && is.data.frame(work_by_zip) && nrow(work_by_zip) > 0) {

  zip_tot <- work_by_zip %>%
    mutate(zipcode = str_pad(gsub("\\D","", as.character(zipcode)), 5, pad = "0")) %>%
    group_by(zipcode) %>%
    summarise(total_orders = sum(n_orders, na.rm = TRUE), .groups = "drop") %>%
    arrange(desc(total_orders)) %>%
    mutate(
      `share of all` = percent(total_orders / sum(total_orders), accuracy = 0.1),
      `total orders` = comma(total_orders)
    ) %>%
    select(zipcode, `total orders`, `share of all`) %>%
    slice_head(n = 25)

  cat("**Table ‚Äì Top 25 ZIP codes by total forestry work orders (NYC Parks)**  \n")
  knitr::kable(zip_tot, align = "c")

} else {
  cat(
"> ‚ö†Ô∏è **Data Note ‚Äî ZIP-Level Summary Unavailable**  \n",
"> The object `work_by_zip` is currently empty.  \n",
"> This usually occurs when the EC#02 end-to-end pipeline hasn‚Äôt been re-run recently  \n",
"> or when the Work Orders dataset lacks valid `zipcode` entries after cleaning.  \n",
"> Once the EC#02 pipeline regenerates the cleaned file, this table will populate automatically."
  )
}
```

#### Findings at a glance

```{r}
#| code-fold: true
#| code-summary: "üìù Automated summary with data check"
#| message: false
#| warning: false
#| results: asis
#| dependson: p6_ec02_end_to_end

suppressPackageStartupMessages({ library(dplyr); library(glue); library(knitr); library(scales) })
# --- Check data availability first ---
if (
  exists("work_by_boro_tot") && is.data.frame(work_by_boro_tot) && nrow(work_by_boro_tot) > 0 &&
  exists("risk_by_boro_tot") && is.data.frame(risk_by_boro_tot) && nrow(risk_by_boro_tot) > 0
) {

  # Identify top boroughs by work orders and inspections
  top_boro_orders  <- work_by_boro_tot |> arrange(desc(n_orders_total)) |> slice(1)
  top_boro_inspect <- risk_by_boro_tot |> arrange(desc(n_inspections_total)) |> slice(1)

  cat(glue(
    "**Findings.** NYC Parks **work orders total** {comma(sum(work_by_boro_tot$n_orders_total))} records ",
    "(2017‚Äìpresent). The highest workload is observed in **{top_boro_orders$borough}** ",
    "with approximately **{comma(top_boro_orders$n_orders_total)}** orders. ",
    "Risk inspections total **{comma(sum(risk_by_boro_tot$n_inspections_total))}**, ",
    "led by **{top_boro_inspect$borough}** (~{comma(top_boro_inspect$n_inspections_total)}). ",
    "These borough-level patterns align with tree-density variations and justify targeted ",
    "maintenance or pruning budgets in the proposal."
  ))

} else {
  cat(
"> ‚ö†Ô∏è **Data Note ‚Äî Summary Unavailable**  \n",
"> One or more summary tables (`work_by_boro_tot` or `risk_by_boro_tot`) are empty.  \n",
"> This typically occurs if the EC#02 end-to-end pipeline has not been executed recently,  \n",
"> or if cleaned datasets were not yet reloaded into memory.  \n",
"> Once the EC#02 process regenerates those tables, this automatic summary will populate here."
  )
}
```

> **Sources.** NYC Open Data ‚Äî *Forestry Risk Assessments* (dataset ID `259a-b6s7`) and *Forestry Work Orders* (dataset ID `bdjm-n7q4`). Downloaded politely with `httr2` using SODA JSON (paged) and cached locally.


### ‚úÖ Submission Checklist
- Render to `docs/mp03.html` (GitHub Pages).  
- ‚ÄúPrint to PDF‚Äù and upload to Brightspace (Optional).  